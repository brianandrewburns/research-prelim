{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "guilty-vegetarian",
   "metadata": {},
   "source": [
    "## Install river and scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "incomplete-utility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./river\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from river==1) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from river==1) (1.6.1)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from river==1) (1.2.3)\n",
      "Requirement already satisfied: sortedcontainers in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from river==1) (2.4.0)\n",
      "Requirement already satisfied: datasketches in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from river==1) (3.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from pandas>=1.0.1->river==1) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from pandas>=1.0.1->river==1) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from python-dateutil>=2.7.3->pandas>=1.0.1->river==1) (1.15.0)\n",
      "Building wheels for collected packages: river\n",
      "  Building wheel for river (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for river: filename=river-1-cp39-cp39-macosx_10_9_x86_64.whl size=1195780 sha256=063aa1c6d588d54b70eda4477e5abfdff7e353a56e9b8ac3353f4324ecf9cc03\n",
      "  Stored in directory: /private/var/folders/s0/cs0fw3px6tx5srp431pdvjc80000gn/T/pip-ephem-wheel-cache-v3adhme2/wheels/d1/6b/a3/83d8a39007debc0733461c491a8263c5af566254c5860a1a1a\n",
      "Successfully built river\n",
      "Installing collected packages: river\n",
      "  Attempting uninstall: river\n",
      "    Found existing installation: river 1\n",
      "    Uninstalling river-1:\n",
      "      Successfully uninstalled river-1\n",
      "Successfully installed river-1\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/Users/brianburns/ml/my_env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"./river/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interested-vector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./scikit-garden\n",
      "Requirement already satisfied: numpy in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from scikit-garden==0.1.3) (1.22.4)\n",
      "Requirement already satisfied: scipy in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from scikit-garden==0.1.3) (1.6.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from scikit-garden==0.1.3) (0.24.1)\n",
      "Requirement already satisfied: cython in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from scikit-garden==0.1.3) (0.29.30)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from scikit-learn>=0.18->scikit-garden==0.1.3) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/brianburns/ml/my_env/lib/python3.9/site-packages (from scikit-learn>=0.18->scikit-garden==0.1.3) (1.0.1)\n",
      "Building wheels for collected packages: scikit-garden\n",
      "  Building wheel for scikit-garden (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for scikit-garden: filename=scikit_garden-0.1.3-cp39-cp39-macosx_10_9_x86_64.whl size=530087 sha256=20fe418083ddcd27e2fd796fb87a854e33f904287695b8362e70b74fd4741980\n",
      "  Stored in directory: /Users/brianburns/Library/Caches/pip/wheels/cc/96/10/f1f98c7ebcbb916ea7b0a696a32ae8d73b3ed876c5d2911053\n",
      "Successfully built scikit-garden\n",
      "Installing collected packages: scikit-garden\n",
      "  Attempting uninstall: scikit-garden\n",
      "    Found existing installation: scikit-garden 0.1.3\n",
      "    Uninstalling scikit-garden-0.1.3:\n",
      "      Successfully uninstalled scikit-garden-0.1.3\n",
      "Successfully installed scikit-garden-0.1.3\n",
      "\u001b[33mWARNING: You are using pip version 21.0.1; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/Users/brianburns/ml/my_env/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install \"./scikit-garden/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sonic-consumer",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "genetic-price",
   "metadata": {},
   "outputs": [],
   "source": [
    "from river import stream\n",
    "from river.ensemble import AdaptiveRandomForestRegressorCP, AdaptiveRandomForestRegressorQRF\n",
    "from skgarden.mondrian import RiverMondrianForestRegressor\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "human-candy",
   "metadata": {},
   "source": [
    "## Experiment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "above-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_variable(file_path):\n",
    "    \"\"\"\n",
    "    Our data files have different names for the target variable.\n",
    "    This returns the string name of the target variable of a dataset in an arff file.\n",
    "    \"\"\"\n",
    "    data_stream = stream.iter_arff(file_path)\n",
    "    v = next(iter(data_stream))\n",
    "    return list(v[0].keys())[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "isolated-humidity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datastream(arff_file):\n",
    "    target_name = get_target_variable(arff_file)\n",
    "    datastream = stream.iter_arff(arff_file, target = target_name)\n",
    "    return datastream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "statewide-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(datastream, dataset_name, models_with_names, metrics_with_names, alpha, parameter_info):\n",
    "    \"\"\"\n",
    "    datastream is a river stream object, not the path of an arff file.\n",
    "    \"\"\"\n",
    "    # Ensure iteration doesn't exhaust datastream\n",
    "    datastream = list(datastream)\n",
    "    \n",
    "    all_results = dict()\n",
    "    all_performances = dict()\n",
    "        \n",
    "    for model, model_name in models_with_names:\n",
    "        results = []\n",
    "        performances = dict()\n",
    "        time_start = time.process_time()\n",
    "        for x,y in datastream:\n",
    "            interval = model.predict_interval(x, alpha)\n",
    "            y_hat = model.predict_one(x)\n",
    "            results.append([x,y,y_hat, interval, alpha])\n",
    "            model.learn_one(x,y)\n",
    "\n",
    "        time_end = time.process_time()\n",
    "        time_elapsed = time_end - time_start\n",
    "        \n",
    "        for metric, metric_name in metrics_with_names:\n",
    "            performances[metric_name] = metric(results)\n",
    "        performances[\"time\"] = time_elapsed\n",
    "        \n",
    "        all_results[model_name] = results\n",
    "        all_performances[model_name] = performances\n",
    "\n",
    "    # Save results and performances\n",
    "    experiment_id = str(datetime.now()).replace(\":\",\"-\").replace(\".\",\"-\").replace(\" \", \"-\")\n",
    "    #save_experiment(dataset_name, all_results, all_performances, alpha, experiment_id, parameter_info)\n",
    "\n",
    "    return all_results, all_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "premium-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experiment(dataset_name, results, performances, alpha, experiment_id, parameter_info):\n",
    "    for model_name in results.keys():\n",
    "        filepath = \"./results/\" + dataset_name + \"/\" + model_name + \"/\" + experiment_id + \"/\"\n",
    "        # Create directory for experiment, if it doesn't already exist\n",
    "        os.makedirs(filepath, exist_ok=True)\n",
    "        # save the result\n",
    "        result = results[model_name]\n",
    "        with open(filepath + \"results.pckl\", \"wb\") as pickle_file:\n",
    "            pickle.dump(results, pickle_file)\n",
    "        # save the metrics\n",
    "        perf = performances[model_name]\n",
    "        with open(filepath + \"metrics.pckl\", \"wb\") as pickle_file:\n",
    "            pickle.dump(perf, pickle_file)\n",
    "        with open(filepath + \"parameters.txt\",\"w\") as params_file:\n",
    "            params_file.writelines(parameter_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-payment",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "conservative-belle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results is a list with elements of the form [x, y, y_hat, interval, alpha]\n",
    "def remove_inf_results(results):\n",
    "    filtered_results = filter(lambda x: x[3][0] != -math.inf and x[3][1] != math.inf, results)\n",
    "    return list(filtered_results)\n",
    "    \n",
    "def mean_error_rate(results):\n",
    "    filtered_results = remove_inf_results(results)\n",
    "    # sum instances where y isn't in confidence interval\n",
    "    s = sum([x[1] < x[3][0] or x[1]> x[3][1] for x in filtered_results])\n",
    "    n = len(filtered_results)\n",
    "    return s/n\n",
    "    \n",
    "\n",
    "def relative_interval_size(results):\n",
    "    filtered_results = remove_inf_results(results)\n",
    "    y_vals = [item[1] for item in filtered_results]\n",
    "    rho = max(y_vals) - min(y_vals)\n",
    "    # sum length of intervals\n",
    "    s = sum(x[3][1] - x[3][0] for x in filtered_results)\n",
    "    n = len(filtered_results)\n",
    "    return s/(rho*n)\n",
    "\n",
    "    \n",
    "def quantile_loss(results):\n",
    "    filtered_results = remove_inf_results(results)\n",
    "    alpha = results[0][4]\n",
    "    a = alpha*relative_interval_size(results)\n",
    "    def single_interval_loss(y, interval):\n",
    "        return max(min(interval)-y, y- max(interval), 0)\n",
    "    s = sum([single_interval_loss(x[1], x[3]) for x in filtered_results])\n",
    "    y_vals = [item[1] for item in filtered_results]\n",
    "    rho = max(y_vals) - min(y_vals)\n",
    "    n = len(filtered_results)\n",
    "    return a + (s/(n*rho))\n",
    "         \n",
    "\n",
    "def utility(results):\n",
    "    filtered_results = remove_inf_results(results)\n",
    "    alpha = results[0][4]\n",
    "    gamma = 2*np.log(2)/alpha\n",
    "    mer = mean_error_rate(results)\n",
    "    ris = relative_interval_size(results)\n",
    "    if mer <= alpha:\n",
    "        return 1-ris\n",
    "    else:\n",
    "        return (1-ris)*np.exp(-gamma*(mer - alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-animation",
   "metadata": {},
   "source": [
    "## Running the experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "economic-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_parameters = \"\"\"Experiment parameters\n",
    "\n",
    "All river models\n",
    "    - n_models = 10\n",
    "    - max_features = \"sqrt\"\n",
    "    - aggregation_method = \"mean\"\n",
    "    - lambda_value = 1\n",
    "\n",
    "OnlineCP\n",
    "    - c_max = 1000\n",
    "\n",
    "OnlineQRF\n",
    "    - K = 200\n",
    "\n",
    "Mondrian forests\n",
    "    - n_estimators = 10\n",
    "    - min_samples_split = 2\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "binary-slave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def instantiate_models():\n",
    "    models_with_names = [\n",
    "        # Mondrian Forest \n",
    "        (RiverMondrianForestRegressor(n_estimators = 10, min_samples_split =2),\n",
    "         \"MondrianForest\"),\n",
    "        # CP Exact\n",
    "#         (AdaptiveRandomForestRegressorCP(n_models = 10, max_features = \"sqrt\", \n",
    "#             aggregation_method = \"mean\", lambda_value = 1, cp_exact = True, c_max = 1000),\n",
    "#          \"CPExact\"),\n",
    "        # CP Approx\n",
    "        (AdaptiveRandomForestRegressorCP(n_models = 10, max_features = \"sqrt\", \n",
    "            aggregation_method = \"mean\", lambda_value = 1, cp_exact = False, c_max = 1000),\n",
    "         \"CPApprox\"),\n",
    "        # OnlineQRF\n",
    "        (AdaptiveRandomForestRegressorQRF(n_models = 10, max_features = \"sqrt\", \n",
    "            aggregation_method = \"mean\", lambda_value = 1, k_sketch = 200),\n",
    "         \"OnlineQRF\"),\n",
    "    ]\n",
    "    return models_with_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "inappropriate-library",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_with_names = [\n",
    "        (mean_error_rate, \"MER\"),\n",
    "        (relative_interval_size, \"RIS\"),\n",
    "        (quantile_loss, \"QL\"),\n",
    "        (utility, \"Utility\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "eleven-oasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = list(load_datastream(\"data/stationary/2dplanes.arff\"))\n",
    "dataset_name = \"2dplanes\"\n",
    "alpha = 0.1\n",
    "models_with_names = instantiate_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "limiting-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_experiment(ds[0:5000], dataset_name, models_with_names, metrics_with_names, alpha, experiment_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "speaking-natural",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_small_experiments(n_repeats):\n",
    "    datasets = os.listdir(\"data/stationary/\")\n",
    "    datasets.remove(\".DS_Store\")\n",
    "    for i in range(n_repeats):\n",
    "        for dataset in datasets:\n",
    "            print(dataset)\n",
    "            models_with_names = instantiate_models()\n",
    "            alpha = 0.1\n",
    "            datastream = list(load_datastream(\"data/stationary/\" + dataset))\n",
    "            dataset_name = dataset.replace(\".arff\",\"\")\n",
    "            run_experiment(datastream, dataset_name, models_with_names, metrics_with_names, alpha, experiment_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "charitable-virgin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n",
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n",
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n",
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n",
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n",
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n",
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n",
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n",
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n",
      "yprop_4_1.arff\n",
      "newsPopularity.arff\n",
      "energy.arff\n",
      "kin8nm.arff\n",
      "elevators.arff\n",
      "cpu_act.arff\n",
      "house_8L.arff\n",
      "puma8NH.arff\n",
      "fried.arff\n",
      "2dplanes.arff\n",
      "calHousing.arff\n",
      "house_16H.arff\n",
      "ailerons.arff\n",
      "sulfur.arff\n"
     ]
    }
   ],
   "source": [
    "run_small_experiments(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "contemporary-memorabilia",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = res[\"AdaptiveRandomForestRegressorQRF\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "olive-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = os.listdir(\"data/stationary/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "endless-minority",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.remove(\".DS_Store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "decimal-password",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['puma32H.arff',\n",
       " 'yprop_4_1.arff',\n",
       " 'abalone.arff',\n",
       " 'mv.arff',\n",
       " 'newsPopularity.arff',\n",
       " 'energy.arff',\n",
       " 'kin8nm.arff',\n",
       " 'elevators.arff',\n",
       " 'bank32nh.arff',\n",
       " 'cpu_act.arff',\n",
       " 'house_8L.arff',\n",
       " 'puma8NH.arff',\n",
       " 'fried.arff',\n",
       " '2dplanes.arff',\n",
       " 'calHousing.arff',\n",
       " 'house_16H.arff',\n",
       " 'ailerons.arff',\n",
       " 'sulfur.arff']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proper-coating",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utility' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-48384efa1752>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mutility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'utility' is not defined"
     ]
    }
   ],
   "source": [
    "utility(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "northern-birth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "True*0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "communist-question",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(0,-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "genuine-mineral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([1,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-recall",
   "metadata": {},
   "source": [
    "## Testing CPApprox timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "christian-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "datastream = list(load_datastream(\"data/stationary/\" + \"2dplanes.arff\"))\n",
    "dataset_name = \"2dplanes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "overhead-empty",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_with_names = [#(AdaptiveRandomForestRegressorCP(n_models = 10, max_features = \"sqrt\", \n",
    "             #aggregation_method = \"mean\", lambda_value = 1, cp_exact = True, c_max = 1000),\n",
    "          #\"CPExact\")\n",
    "                    (RiverMondrianForestRegressor(n_estimators = 10, min_samples_split =2),\n",
    "         \"MondrianForest\")\n",
    "                    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "seeing-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_with_names = [\n",
    "        (mean_error_rate, \"MER\"),\n",
    "        (relative_interval_size, \"RIS\"),\n",
    "        (quantile_loss, \"QL\"),\n",
    "        (utility, \"Utility\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "controlled-construction",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "brilliant-soldier",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_and_perf = run_experiment(datastream[4001:5000], dataset_name, models_with_names, metrics_with_names, alpha, experiment_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "crucial-tampa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MondrianForest': {'MER': 0.12712712712712712,\n",
       "  'RIS': 0.291950277255733,\n",
       "  'QL': 0.03453494973727581,\n",
       "  'Utility': 0.48611853211072303,\n",
       "  'time': 8.894488000000024}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_and_perf[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-intersection",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
